\subsection{Bidirectional UDP 1 Gbit/s (500+500 Mbit/s)}
In this scenario, the DUT is exposed to a bidirectional UDP traffic load of 1\,Gbit/s, consisting of 64-bytes packets, generated by TRex using the \textit{udp\_1pkt\_src\_ip\_split.py} profile. 
This configuration ensures that each packet carries a unique source IP address, simulating multiple clients while maintaining a single destination per direction. 
The routing table of the DUT contains only two active forwarding entries, corresponding to the test routes, in addition to two administrative entries used for management. 
The aim of this test is to observe the behavior of the VPP forwarding plane under low traffic load and to evaluate its energy efficiency, 
specifically in terms of packet-per-watt cost under realistic but unsaturated conditions.

The chosen load of 1 Gbit/s is representative of a realistic aggregate traffic pattern that could be observed in a small or medium-sized enterprise network, especially when routed through a central gateway.
The use of 64-byte packets represents a common worst-case scenario in packet forwarding, as such small packets are typical of control-plane messages, e. g. ACKs in TCP traffic. 
These packets put increased stress on the processing path due to their higher packet-per-second rate for a given bandwidth, thereby providing a stringent test of the forwarding plane's efficiency

The DUT is configured with the Vector Packet Processing (VPP) stack, tested under three configurations using 1, 4, and 10 worker threads. 
The number of RX/TX queues is aligned with the number of active worker threads in each case to ensure balanced packet distribution and optimal performance. 
For each configuration, the same traffic pattern is replayed to measure how well the VPP-based router handles low traffic load under different degrees of parallelism.

As a baseline for comparison, the scenario is also executed using a standard Linux network stack, configured with similar routing and interface parameters. 
This enables a direct comparison between VPP and traditional kernel-based forwarding in terms of performance and power efficiency.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Scenario} & \textbf{TX Packets} & \textbf{TX Bytes} & \textbf{Watts used} \\
\hline
VPP -- 1 worker & 17 578 124 988 & 1 124 999 999 232 & 25 442.4 \\
VPP -- 4 workers & 17 578 124 986 & 1 124 999 999 104 & 28 531 \\
VPP -- 10 workers &  17 578 124 988 & 1 124 999 999 232 & 35 806.8 \\
Linux stack & 17 578 124 978 & 1 124 999 998 592 & 37 717.4 \\
\hline
\end{tabular}
\caption{Result of Bidirectional UDP 1 Gbit/s test}
\label{tab:udp:one}
\end{table}

As the results in Table \ref{tab:udp:one} show, the power consumption increases notably with the number of worker threads in the VPP stack. 
While all VPP configurations deliver identical packet and byte throughput, the most energy-efficient setup is this measurement is the single-worker variant, consuming roughly 25.4 kWh during the test. 
In contrast, the traditional Linux network stack demonstrates the highest energy usage, despite handling the same volume of packets.

This discrepancy can likely be attributed to the cost of processing a high number of small packets in kernel space. 
Since the test uses fixed-size 64-byte packets, which are known to generate frequent system calls and context switches in Linux, 
the forwarding path becomes less efficient compared to VPP’s user-space architecture, where such overheads are significantly reduced. 
The results highlight the energy cost of kernel-based packet forwarding in scenarios dominated by small-packet traffic.

