\subsection{Bidirectional UDP 1 Gbit/s of 64-bytes packets}
In this scenario, the DUT is exposed to a bidirectional UDP traffic load of 1\,Gbit/s combined (500+500 Mbit/s), 
consisting of 64-bytes packets, generated by TRex using the \textit{udp\_1pkt\_src\_ip\_split.py} profile. 
This configuration ensures that each packet carries a unique source IP address, simulating multiple clients while maintaining a single destination per direction. 
The routing table of the DUT contains only two active forwarding entries, corresponding to the test routes, in addition to two administrative entries used for management. 
The aim of this test is to observe the behavior of the VPP forwarding plane under low traffic load of small packets and to evaluate its energy efficiency.

The chosen load of 1 Gbit/s is representative of a realistic aggregate traffic pattern that could be observed in a small or medium-sized enterprise network, especially when routed through a central gateway.
The use of 64-byte packets represents a worst-case scenario in packet forwarding, as processing such small packets means to process a large amount non-payload data. 
These packets put increased stress on the processing path due to their higher packet-per-second rate for a given bandwidth, thereby providing a stringent test of the forwarding plane's efficiency

The DUT is configured with the Vector Packet Processing (VPP) stack, tested under three configurations using 1, 4, and 10 worker threads. 
The number of RX/TX queues is aligned with the number of active worker threads in each case to ensure balanced packet distribution and optimal performance. 
For each configuration, the same traffic pattern is replayed to measure how well the VPP-based router handles low traffic load under different degrees of parallelism.

As a baseline for comparison, the scenario is also executed using a standard Linux network stack, configured with similar routing and interface parameters. 
This enables a direct comparison between VPP and traditional kernel-based forwarding in terms of performance and power efficiency.

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Configuration} & \textbf{Transmited packets} & \textbf{Transmited bytes} & \textbf{Watts used} \\
\hline
VPP -- 1 worker & 17 578 124 988 & 1 124 999 999 232 & 848.08 \\
VPP -- 4 workers & 17 578 124 986 & 1 124 999 999 104 & 951.03 \\
VPP -- 10 workers &  17 578 124 988 & 1 124 999 999 232 & 1 193.56 \\
Linux stack & 17 578 124 978 & 1 124 999 998 592 & 1 257.25 \\
\hline
\end{tabular}
\caption{Result of Bidirectional UDP 1 Gbit/s of 870-bytes packets test}
\label{tab:udp:one}
\end{table}

As the results in Table \ref{tab:udp:one} show, the power consumption increases notably with the number of worker threads in the VPP stack. 
While all VPP configurations deliver identical packet and byte throughput, the most energy-efficient setup is this measurement is the single-worker variant, consuming roughly 25.4 kWh during the test. 
In contrast, the traditional Linux network stack demonstrates the highest energy usage, despite handling the same volume of packets.

This discrepancy can likely be attributed to the cost of processing a high number of small packets in kernel space. 
Since the test uses fixed-size 64-byte packets, which are known to generate frequent system calls and context switches in Linux, 
the forwarding path becomes less efficient compared to VPP’s user-space architecture, where such overheads are significantly reduced. 
The results highlight the energy cost of kernel-based packet forwarding in scenarios dominated by small-packet traffic.

\subsection{Bidirectional UDP 1 Gbit/s of 870-bytes packets}

In this scenario, the DUT is subjected to a bidirectional UDP traffic load of 1\,Gbit/s (500+500\,Mbit/s) composed of 870-byte packets, 
generated using a modified TRex \textit{udp\_1pkt\_src\_ip\_split.py} profile. 
The packet size of 870 bytes is used becuase it was identified as the average size in real-world network traffic by Jurkiewicz et al.~\cite{JURKIEWICZ202115}.

This test complements the previous one by simulating a more typical traffic pattern, as opposed to the stress scenario represented by minimal 64-byte packets. 
Larger packets result in a lower packet-per-second (PPS) rate for the same bandwidth, thus reducing per-packet processing overhead and more closely reflecting actual router workloads.

The DUT is again configured with the VPP stack and evaluated under three different worker thread configurations (1, 4, and 10), with queue allocation matching the thread count. 
The Linux kernel-based router is also included in the comparison under equivalent conditions.

This scenario provides insight into forwarding and energy efficiency under more realistic conditions, allowing for better interpretation of the DUT’s performance in practical deployments.


\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Configuration} & \textbf{Transmited packets} & \textbf{Transmited bytes} & \textbf{Watts used} \\
\hline
VPP -- 1 worker & 1 293 103 500 & 1 125 000 045 000 & 823.20\\
VPP -- 4 workers & 1 293 103 500 & 1 125 000 045 000 & 972.49\\
VPP -- 10 workers & 1 293 103 500 & 1 125 000 045 000 & 1 170.26\\
Linux stack & 1 293 103 500 & 1 125 000 045 000 & 946.28\\
\hline
\end{tabular}
\caption{Result of Bidirectional UDP 1 Gbit/s of 870-bytes packets test}
\label{tab:udp:two}
\end{table}

As shown in table \ref{tab:udp:two}, the second test with 870-byte packets, 
VPP's power consumption remains relatively stable across different worker thread configurations, with a variation of only about ±5\% compared to previous measurement. 
This indicates that VPP's performance and power consumption are consistent, regardless of the increased packet size. 
On the other hand, the Linux stack's power consumption shows a positive reduction compared to the previous test, which is attributed to the lower number of packets being processed. 
Since larger packets reduce the packet-per-second (PPS) rate, the system overhead and processing cost in Linux are lower, leading to more efficient energy usage in this scenario.











